{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "import math\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MSE,MDcR,DSE,MVBG,CPCA,DPCA,MVP,LPP,LE\n",
    "import scipy\n",
    "datasets_names = ['BBC','MSRC-v1','NGs','Reuters','YALE']\n",
    "# datasets_names = ['Reuters']\n",
    "\n",
    "for dt_name in datasets_names:\n",
    "    # data\n",
    "    X,labels=read_data(f'datasets/data sets/{dt_name}.mat')\n",
    "    X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "    X =  [x[:300,:500] for x in X] #d<=300 ,n = X[0].shape[1]\n",
    "    if isinstance(X[0],scipy.sparse._csr.csr_matrix):\n",
    "        X =   [np.asarray(x.todense()) for x in X]\n",
    "    labels  = labels.squeeze()\n",
    "    k = len(set(labels))\n",
    "    #models\n",
    "    model_list =  [MSE(), MDcR(),DSE(),MVBG(0.1,2,0.1), CPCA(),DPCA(), MVP(),LPP(),LE()]\n",
    "    #main \n",
    "    res_nmi = [];res_acc =[];res_ari=[];res_purity  = []\n",
    "    train_ratio=0.1\n",
    "    d_max  =  min(math.floor((1-train_ratio)*X[0].shape[1]),int(np.min([x.shape[0] for x in X])) ) #min(d,測試x的維數)\n",
    "    d_range  = range(k,d_max)\n",
    "    model  =  MDcR()\n",
    "\n",
    "    for d_ in tqdm(d_range): \n",
    "        nmi_list = [];acc_list =[]; ari_list=[]; purity_list=[]\n",
    "        for i in range(5):\n",
    "            # train_test split\n",
    "            train_idx,test_idx = random_index(X[0].shape[1],train_ratio)\n",
    "            X_train = [x[:,train_idx] for x in X]\n",
    "            X_test = [x[:,test_idx] for x in X]\n",
    "            y_test = labels[test_idx]\n",
    "            #train\n",
    "\n",
    "            # pred =  model.predict(X_test,0.5,2,1e6,d_,k,10) #MVP ok\n",
    "            # pred   = model.predict(X_train,X_test,1e7,d_,k,200) #lPP ok \n",
    "            # pred  = model.predict(X_test,d_,20,k) #LE ok\n",
    "            # pred = model.predict(X_train,X_test,d_,k) #DPCA ok\n",
    "            # pred =  model.predict(X_test,0.5,d_,1e8,k,100) #MSE ok\n",
    "            pred   =  model.predict(X_test,d_,1e8,5,100,100)#mdcr ok\n",
    "            # pred = model.predict(X_test,d_max,d_,k,1e8,30)# m: >=dmax ok mvbg\n",
    "            # pred = model.dse(X_test,k,2,100) #dse \n",
    "            # pred  = model.predict(X_train, X_test,d_,k) #CPCA\n",
    "            # criterion\n",
    "            #nmi\n",
    "            from sklearn.metrics.cluster import normalized_mutual_info_score,adjusted_rand_score\n",
    "            from sklearn.metrics import homogeneity_score\n",
    "\n",
    "            nmi = normalized_mutual_info_score(y_test,pred)\n",
    "            nmi_list.append(nmi)\n",
    "            #acc\n",
    "            acc =   acc_score(y_test,pred)\n",
    "            acc_list.append(acc)\n",
    "            #ari\n",
    "            ari =   adjusted_rand_score(y_test,pred)\n",
    "            ari_list.append(ari)\n",
    "            #purity\n",
    "            purity  =  purity_score(y_test,pred)\n",
    "            purity_list.append(purity)\n",
    "        #\n",
    "        nmi = np.mean(nmi_list)\n",
    "        acc  = np.mean(acc_list)\n",
    "        ari = np.mean(ari_list)\n",
    "        purity = np.mean(purity_list)\n",
    "        # \n",
    "        res_nmi.append(nmi)\n",
    "        res_acc.append(acc)\n",
    "        res_ari.append(ari)\n",
    "        res_purity.append(purity)\n",
    "    np.save(f'./result/nmi/{dt_name}/{model.name}.npy',res_nmi)\n",
    "    np.save(f'./result/acc/{dt_name}/{model.name}.npy',res_acc)\n",
    "    np.save(f'./result/ari/{dt_name}/{model.name}.npy',res_ari)\n",
    "    np.save(f'./result/purity/{dt_name}/{model.name}.npy',res_purity)\n",
    "\n",
    "    #plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.plot(d_range,res_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "import math\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MVBG\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "datasets_names = ['BBC','MSRC-v1','NGs','Reuters','YALE']\n",
    "# datasets_names=['YALE']\n",
    "alpha = [0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "beta = [0.001,0.01,0.1,1,10,100,1000]\n",
    "gamma = [1.2, 1.5, 1.8, 2, 4, 6, 8, 10] \n",
    "\n",
    "d_ = 20\n",
    "for dt_name in tqdm(datasets_names):\n",
    "    # data\n",
    "    X,labels=read_data(f'datasets/mats/{dt_name}.mat')\n",
    "    X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "    X =  [x[:600,:1000] for x in X] #d<=300 ,n = X[0].shape[1]\n",
    "    if isinstance(X[0],scipy.sparse._csr.csr_matrix):\n",
    "        X =   [np.asarray(x.todense()) for x in X]\n",
    "    labels  = labels.squeeze()\n",
    "    k = len(set(labels))\n",
    "    train_ratio=0.1\n",
    "    acc = []\n",
    "    for b in beta:\n",
    "    # for a in alpha:\n",
    "    # for g in gamma:\n",
    "        # train_test split\n",
    "        train_idx,test_idx = random_index(X[0].shape[1],train_ratio)\n",
    "        X_train = [x[:,train_idx] for x in X]\n",
    "        X_test = [x[:,test_idx] for x in X]\n",
    "        y_test = labels[test_idx]\n",
    "        #train\n",
    "        # model=MVBG(alpha[0],g,beta[0])\n",
    "        model =   MVBG(alpha[0],gamma[0],b)\n",
    "        # model   = MVBG(a,gamma[0],beta[0])\n",
    "\n",
    "        pred = model.predict(X_test,50,d_,k,1e6,10)# m: >=dmax ok mvbg\n",
    "        #accuracy\n",
    "        acc.append(acc_score(y_test,pred))\n",
    "        # print(a)\n",
    "    \n",
    "    plt.plot(alpha,acc,label=f\"{dt_name}\")\n",
    "    plt.scatter(alpha,acc)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('acc with increaing alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score,homogeneity_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import *\n",
    "a = np.array([1,1,2,2,3,3])\n",
    "b = np.array([3,3,1,2,3,1])\n",
    "# b  = np.array([1,1,3,2,1,3])\n",
    "\n",
    "adjusted_rand_score(a,b)\n",
    "# purity_score(b,b)\n",
    "purity_score(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "X,labels=read_data(f'datasets/data sets/Reuters.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "np.asarray(X[2].todense()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./result/NGs/mvbg_nmi.npy',res_nim)\n",
    "res_nmi = np.load('./result/nmi/YALE/nmi_DPCA.npy')\n",
    "res_nmi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
