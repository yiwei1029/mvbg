{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/294 [00:16<15:01,  3.12s/it]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "import math\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MSE,MDcR,DSE,MVBG,CPCA,DPCA,MVP,LPP,LE\n",
    "import scipy\n",
    "datasets_names = ['BBC','MSRC-v1','NGs','Reuters','YALE']\n",
    "datasets_names = ['Reuters']\n",
    "\n",
    "for dt_name in datasets_names:\n",
    "    # data\n",
    "    X,labels=read_data(f'datasets/data sets/{dt_name}.mat')\n",
    "    X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "    X =  [x[:300,] for x in X] #d<=300 ,n = X[0].shape[1]\n",
    "    if isinstance(X[0],scipy.sparse._csr.csr_matrix):\n",
    "        X =   [np.asarray(x.todense()) for x in X]\n",
    "    labels  = labels.squeeze()\n",
    "    k = len(set(labels))\n",
    "    #models\n",
    "    model_list =  [MSE(), MDcR(),DSE(),MVBG(0.1,2,0.1), CPCA(),DPCA(), MVP(),LPP(),LE()]\n",
    "    #main \n",
    "    res_nmi = [];res_acc =[];res_ari=[];res_purity  = []\n",
    "    train_ratio=0.1\n",
    "    d_max  =  min(math.floor((1-train_ratio)*X[0].shape[1]),int(np.min([x.shape[0] for x in X])) ) #min(d,測試x的維數)\n",
    "    d_range  = range(k,d_max)\n",
    "    model  =  CPCA()\n",
    "\n",
    "    for d_ in tqdm(d_range): \n",
    "        nmi_list = [];acc_list =[]; ari_list=[]; purity_list=[]\n",
    "        for i in range(1):\n",
    "            # train_test split\n",
    "            train_idx,test_idx = random_index(X[0].shape[1],train_ratio)\n",
    "            X_train = [x[:,train_idx] for x in X]\n",
    "            X_test = [x[:,test_idx] for x in X]\n",
    "            y_test = labels[test_idx]\n",
    "            #train\n",
    "\n",
    "            # pred =  model.predict(X_test,0.5,2,1e6,d_,k,10) #MVP ok\n",
    "            # pred   = model.predict(X_train,X_test,1e7,d_,k,200) #lPP ok \n",
    "            # pred  = model.predict(X_test,d_,20,k) #LE ok\n",
    "            # pred = model.predict(X_train,X_test,d_,k) #DPCA ok\n",
    "            # pred =  model.predict(X_test,0.5,d_,1e8,k,100) #MSE ok\n",
    "            # pred   =  model.predict(X_test,d_,1e8,5,100,100)#mdcr ok\n",
    "            # pred = model.predict(X_test,d_max,d_,k,1e8,30)# m: >=dmax ok mvbg\n",
    "            # pred = model.dse(X_test,k,2,100) #dse \n",
    "            pred  = model.predict(X_train, X_test,d_,k)\n",
    "            # criterion\n",
    "            #nmi\n",
    "            from sklearn.metrics.cluster import normalized_mutual_info_score,adjusted_rand_score\n",
    "            from sklearn.metrics import homogeneity_score\n",
    "\n",
    "            nmi = normalized_mutual_info_score(y_test,pred)\n",
    "            nmi_list.append(nmi)\n",
    "            #acc\n",
    "            acc =   acc_score(y_test,pred)\n",
    "            acc_list.append(acc)\n",
    "            #ari\n",
    "            ari =   adjusted_rand_score(y_test,pred)\n",
    "            ari_list.append(ari)\n",
    "            #purity\n",
    "            purity  =  purity_score(y_test,pred)\n",
    "            purity_list.append(purity)\n",
    "        #\n",
    "        nmi = np.mean(nmi_list)\n",
    "        acc  = np.mean(acc_list)\n",
    "        ari = np.mean(ari_list)\n",
    "        purity = np.mean(purity_list)\n",
    "        # \n",
    "        res_nmi.append(nmi)\n",
    "        res_acc.append(acc)\n",
    "        res_ari.append(ari)\n",
    "        res_purity.append(purity)\n",
    "    np.save(f'./result/nmi/{dt_name}/{model.name}.npy',res_nmi)\n",
    "    np.save(f'./result/acc/{dt_name}/{model.name}.npy',res_acc)\n",
    "    np.save(f'./result/ari/{dt_name}/{model.name}.npy',res_ari)\n",
    "    np.save(f'./result/purity/{dt_name}/{model.name}.npy',res_purity)\n",
    "\n",
    "    #plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.plot(d_range,res_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\Documents\\machine_learning_projects\\main.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Documents/machine_learning_projects/main.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#train\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Documents/machine_learning_projects/main.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model\u001b[39m=\u001b[39mMVBG(a,gamma[\u001b[39m0\u001b[39m],beta[\u001b[39m0\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pc/Documents/machine_learning_projects/main.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test,\u001b[39m20\u001b[39m,d_,k,\u001b[39m1e6\u001b[39m,\u001b[39m30\u001b[39m)\u001b[39m# m: >=dmax ok mvbg\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Documents/machine_learning_projects/main.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#accuracy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Documents/machine_learning_projects/main.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m acc\u001b[39m.\u001b[39mappend(acc_score(y_test,pred))\n",
      "File \u001b[1;32mc:\\Users\\pc\\Documents\\machine_learning_projects\\models.py:48\u001b[0m, in \u001b[0;36mMVBG.predict\u001b[1;34m(self, X, m, d_, n_clusters, t, epoch)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m,X, m,d_,n_clusters,t,epoch):\n\u001b[1;32m---> 48\u001b[0m     P \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmvbg(X, m,d_,t,epoch)\n\u001b[0;32m     49\u001b[0m     prob \u001b[39m=\u001b[39m kmeans(P,n_clusters)\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m prob\n",
      "File \u001b[1;32mc:\\Users\\pc\\Documents\\machine_learning_projects\\models.py:33\u001b[0m, in \u001b[0;36mMVBG.mvbg\u001b[1;34m(self, X, m, d_, t, epoch)\u001b[0m\n\u001b[0;32m     31\u001b[0m D_G\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39msum(Z,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     32\u001b[0m A_temp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(np\u001b[39m.\u001b[39msqrt(D_F))\u001b[39m.\u001b[39mdot(Z\u001b[39m.\u001b[39mT)\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(np\u001b[39m.\u001b[39msqrt(D_G))) \u001b[39m#for SVD\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m u_A,s_A,v_A \u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msvd(A_temp)\n\u001b[0;32m     34\u001b[0m F \u001b[39m=\u001b[39m u_A[:,:d_]\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     35\u001b[0m G \u001b[39m=\u001b[39m v_A[:d_,:]\u001b[39m.\u001b[39mT\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Soft\\Anaconda\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1642\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1639\u001b[0m         gufunc \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39msvd_n_s\n\u001b[0;32m   1641\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->DdD\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->ddd\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1642\u001b[0m u, s, vh \u001b[39m=\u001b[39m gufunc(a, signature\u001b[39m=\u001b[39msignature, extobj\u001b[39m=\u001b[39mextobj)\n\u001b[0;32m   1643\u001b[0m u \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1644\u001b[0m s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mastype(_realType(result_t), copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Soft\\Anaconda\\Lib\\site-packages\\numpy\\linalg\\linalg.py:98\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSVD did not converge\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "import math\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MVBG\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "datasets_names = ['BBC','MSRC-v1','NGs','Reuters','YALE']\n",
    "alpha = [0.001,0.01,0.1,1,10,100,1000]\n",
    "beta = [0.001,0.01,0.1,1,10,100,1000]\n",
    "gamma = [1.2, 1.5, 1.8, 2, 4, 6, 8, 10] \n",
    "\n",
    "d_ = 20\n",
    "for dt_name in tqdm(datasets_names):\n",
    "    # data\n",
    "    X,labels=read_data(f'datasets/data sets/{dt_name}.mat')\n",
    "    X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "    X =  [x[:300,] for x in X] #d<=300 ,n = X[0].shape[1]\n",
    "    if isinstance(X[0],scipy.sparse._csr.csr_matrix):\n",
    "        X =   [np.asarray(x.todense()) for x in X]\n",
    "    labels  = labels.squeeze()\n",
    "    k = len(set(labels))\n",
    "    train_ratio=0.1\n",
    "    acc = []\n",
    "    for a in alpha:\n",
    "        # train_test split\n",
    "        train_idx,test_idx = random_index(X[0].shape[1],train_ratio)\n",
    "        X_train = [x[:,train_idx] for x in X]\n",
    "        X_test = [x[:,test_idx] for x in X]\n",
    "        y_test = labels[test_idx]\n",
    "        #train\n",
    "        model=MVBG(a,gamma[0],beta[0])\n",
    "        pred = model.predict(X_test,20,d_,k,1e6,30)# m: >=dmax ok mvbg\n",
    "        #accuracy\n",
    "        acc.append(acc_score(y_test,pred))\n",
    "\n",
    "    plt.plot(alpha,acc)\n",
    "    plt.title(dt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score,homogeneity_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import *\n",
    "a = np.array([1,1,2,2,3,3])\n",
    "b = np.array([3,3,1,2,3,1])\n",
    "# b  = np.array([1,1,3,2,1,3])\n",
    "\n",
    "adjusted_rand_score(a,b)\n",
    "# purity_score(b,b)\n",
    "purity_score(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "X,labels=read_data(f'datasets/data sets/Reuters.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "np.asarray(X[2].todense()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./result/NGs/mvbg_nmi.npy',res_nim)\n",
    "res_nmi = np.load('./result/nmi/YALE/nmi_DPCA.npy')\n",
    "res_nmi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
