{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MSE,MDcR,DSE,MVBG,CPCA,DPCA,MVP,LPP,LE\n",
    "import scipy\n",
    "datasets_names = ['BBC','MSRC-v1','NGs','Reuters','YALE']\n",
    "datasets_names = ['Reuters','YALE']\n",
    "\n",
    "for dt_name in datasets_names:\n",
    "    # data\n",
    "    X,labels=read_data(f'datasets/data sets/{dt_name}.mat')\n",
    "    X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "    X =  [x[:300,:] for x in X]\n",
    "\n",
    "    if isinstance(X[0],scipy.sparse._csr.csr_matrix):\n",
    "        X =   [np.asarray(x.todense()) for x in X]\n",
    "    labels  = labels.squeeze()\n",
    "    k = len(set(labels))\n",
    "    #models\n",
    "    model_MSE = MSE()\n",
    "    model_MDcR = MDcR()\n",
    "    model_DSE = DSE()\n",
    "    model_MVBG = MVBG(0.1,2,0.1)\n",
    "    model_CPCA = CPCA()\n",
    "    model_DPCA = DPCA()\n",
    "    model_MVP =  MVP()\n",
    "    model_LPP   =   LPP()\n",
    "    model_LE = LE()\n",
    "    #main \n",
    "    res_nmi = []\n",
    "    d_max  =   int(1*np.min([x.shape[0] for x in X]))\n",
    "    d_range  = range(k,d_max)\n",
    "    model = model_DPCA\n",
    "\n",
    "    for d_ in tqdm(d_range): \n",
    "        nmi_list = []\n",
    "        for i in range(5):\n",
    "            # train_test split\n",
    "            train_idx,test_idx = random_index(X[0].shape[1],0.8)\n",
    "            X_train = [x[:,train_idx] for x in X]\n",
    "            X_test = [x[:,test_idx] for x in X]\n",
    "            y_test = labels[test_idx]\n",
    "            #train\n",
    "\n",
    "            # pred =  model.predict(X_test,0.5,2,1e6,d_,k,10) #MVP\n",
    "            # pred   = model.predict(X_train,X_test,1e7,d_,k,200) #lPP ok too slow\n",
    "            # pred  = model.predict(X_train,X_test,d_,20,k) #LE ok\n",
    "            pred = model.predict(X_train,X_test,d_,k)\n",
    "\n",
    "            # criterion\n",
    "            from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "            nmi = normalized_mutual_info_score(y_test,pred)\n",
    "            nmi_list.append(nmi)\n",
    "        nmi = np.mean(nmi_list)\n",
    "        res_nmi.append(nmi)\n",
    "    np.save(f'./result/{dt_name}/nmi_{model.name}.npy',res_nmi)\n",
    "    #plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(3,2))\n",
    "    plt.plot(d_range,res_nmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    ind = linear_sum_assignment(w.max() - w)\n",
    "    ind = np.array(ind).T\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size\n",
    "\n",
    "import numpy as np\n",
    "a = np.array([1,1,2,2,3,3])\n",
    "b = np.array([3,3,1,2,3,1])\n",
    "# b  = np.array([1,1,3,2,1,3])\n",
    "\n",
    "adjusted_rand_score(a,b)\n",
    "accuracy_score(a,b)\n",
    "acc(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "X,labels=read_data(f'datasets/data sets/Reuters.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "np.asarray(X[2].todense()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./result/NGs/mvbg_nmi.npy',res_nim)\n",
    "res_nmi = np.load('./result/YALE/nmi_DPCA.npy')\n",
    "res_nmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MVBG\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#model and \n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from models import MSE,MDcR,DSE,MVBG,PCA\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "X,labels=read_data('datasets/data sets/NGs.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "labels  = labels.squeeze()\n",
    "\n",
    "d_range = (10,12)\n",
    "model_mvbg = MVBG(0.1,2,0.1)\n",
    "res_nmi = []\n",
    "for d_ in d_range:\n",
    "    nmi_list=[]\n",
    "    for _ in range(1):\n",
    "        dim_emb = model_mvbg.mvbg(X,100,d_,10)\n",
    "        pred =kmeans(dim_emb,7)\n",
    "        nmi_temp = normalized_mutual_info_score(labels, pred)\n",
    "        nmi_list.append(nmi_temp)\n",
    "    nmi = np.mean(nmi_list)\n",
    "    res_nmi.append(nmi)\n",
    "print(res_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DSE 單獨\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "X,labels=read_data('datasets/data sets/YALE.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "labels  = labels.squeeze()\n",
    "\n",
    "from models import DSE\n",
    "model_DSE = DSE()\n",
    "nmi_list=[]\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "\n",
    "    pred = model_DSE.dse(X,7,2,500)\n",
    "    from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "    nmi = normalized_mutual_info_score(labels,pred)\n",
    "    # print(nmi)\n",
    "    nmi_list.append(nmi)\n",
    "print(np.mean(nmi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.rand(3,4)\n",
    "np.exp(x)/np.exp(x).sum(1).reshape(3,-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
