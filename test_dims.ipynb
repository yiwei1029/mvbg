{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[2,3,2]])\n",
    "U,sigma,VT = np.linalg.svd(data)\n",
    "print(U,U.shape)\n",
    "print(VT,VT.shape)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mat = np.random.rand(100,400) #(d,n)\n",
    "\n",
    "def pca(mat):\n",
    "    mat = mat-mat.mean(axis=1).reshape(-1,1)\n",
    "    cov = np.dot(mat,mat.T)\n",
    "    eigval,eigvec = np.linalg.eig(cov)\n",
    "    idx = np.argpartition(eigval,-50)[-50:]\n",
    "    w = eigvec[:,idx] #\n",
    "    out = w.T.dot(mat)\n",
    "    print(w.shape)\n",
    "    print(np.rint(w.T.dot(w)))#validate that W*W.T=I\n",
    "pca(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([2,1,4,3])\n",
    "idx = np.argpartition(a1,3)\n",
    "print(idx)\n",
    "a1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3],[3,4,5],[4,5,6],[7,8,9]])\n",
    "aa = np.array([a,a])\n",
    "b = np.array([1,2])\n",
    "# print(aa)\n",
    "# np.linalg.multi_dot([aa,b])\n",
    "# np.diag(a.sum(axis=1))\n",
    "# np.sqrt(a)\n",
    "# np.linalg.inv(np.sqrt(a)).dot(np.sqrt(a))\n",
    "u,s,vh=np.linalg.svd(a)\n",
    "print(u.shape,s.shape,vh.shape)\n",
    "u[:,:2].dot(np.diag(s[:2])).dot(vh[:2,:])\n",
    "# np.concatenate([a,a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate pairwise similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,1],[2,2],[3,3]]) #3,2\n",
    "b = np.array([[3,3],[4,4]]) #2,2\n",
    "a_til = np.tile(np.expand_dims(a,1),[1,2,1])\n",
    "b_til = np.tile(np.expand_dims(b,0),[3,1,1])\n",
    "np.square(a_til-b_til).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,1],[2,2],[3,3]])\n",
    "b = np.array([[1],[2],[3]])\n",
    "a*b\n",
    "diag = 1/np.diagonal(np.array([[1,2],[3,4]])).reshape(-1,1)\n",
    "diag\n",
    "\n",
    "a = np.array([[1,2],[3,4]])\n",
    "aa = np.array([a,a,a])\n",
    "sum([a,a,a])\n",
    "np.where(a[:,1]>0,a[:,1],0)\n",
    "np.random.rand()+1\n",
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = np.array([0.5,0.7,0.3,1,0.9])\n",
    "for p in np.linspace(-0.9,0.9,10000):\n",
    "    sum_ = np.where(k+p>0,k+p,0).sum()\n",
    "    if(np.abs(sum_-1)<1e-2):\n",
    "        break\n",
    "    \n",
    "print(p,sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "img = Image.open('101_0108.JPG')\n",
    "img_ = np.asarray(img.convert('L')) \n",
    "print(type(img_ ))\n",
    "# Image.fromarray(img_).save('1.png')\n",
    "Image.fromarray(img_).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reshape tensor or array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "a = np.array([[[1,2],[3,4]],[[5,6],[7,8]],[[9,10],[11,12]]])\n",
    "a.transpose(2,0,1).shape\n",
    "\n",
    "b = np.random.rand(3,3,1)\n",
    "c = np.random.rand(3,3,1)\n",
    "np.concatenate([b,c],axis=2)\n",
    "np.expand_dims(b,axis=1).shape\n",
    "a = np.arange(12).reshape(2,3,2)\n",
    "b.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as scio\n",
    "filepath =  './datasets/data sets/MSRC-v1.mat'\n",
    "data = scio.loadmat(filepath)\n",
    "data['X'][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soft\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "d:\\Soft\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "X,labels=read_data('datasets/data sets/MSRC-v1.mat')\n",
    "X = [X[0,i].T for  i  in range(X.shape[1])]\n",
    "from models import MSE\n",
    "MSE = MSE()\n",
    "Y = MSE.mse(X,0.5,120,10000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soft\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "d:\\Soft\\Anaconda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06607041098347122\n"
     ]
    }
   ],
   "source": [
    "pred = kmeans(Y,7)\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "nmi = normalized_mutual_info_score(labels.squeeze(),pred)\n",
    "print(nmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
